{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Just ignore cells prefaced with \"--- TEST ---\", they're there for debugging. Thanks! - BRB \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# DOST AI Summer School 2017\n",
    "# Multinomial Naive Bayes Spam Classifier\n",
    "\n",
    "Prepared by Jerelyn Co (ADMU) and Hadrian Paulo Lim (ADMU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Practicals: Spam Filtering with Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models\n",
    "7. Examining a model for further insight\n",
    "9. Tuning the vectorizer (challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "# using the variable name vect\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "# by calling vect.fit() on the simple_train array\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "# using the transform() method of vect on the simple_train array\n",
    "# Assign the result to a variable simple_train_dtm\n",
    "simple_train_dtm = vect.transform(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "# assign the DataFrame object to a variable called spam_ham.\n",
    "# Use the extra parameters: header=0, names=['label', 'location','message']\n",
    "# for the read function\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = None\n",
    "# Drop entries with null values using dropna(inplace=True) on your DataFrame\n",
    "spam_ham = pd.read_csv(path, header=0, names=['label', 'location', 'message'])\n",
    "spam_ham = spam_ham.drop('location', axis=1)\n",
    "spam_ham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30974, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "# You should get (30974, 2)\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  Academic Qualifications available from prestig...\n",
       "2   ham  Greetings all. This is to verify your subscrip...\n",
       "3  spam  try chauncey may conferred the luscious not co...\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  It's working here. I have departed almost tota...\n",
       "6  spam  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19280\n",
       "ham     11694\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert the labels to a numerical variable\n",
    "# where ham is reassigned to 0, and spam is 1.\n",
    "# The converted labels should be under the label_num column.\n",
    "spam_ham['label_num'] = spam_ham.label.map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...          1\n",
       "1  spam  Academic Qualifications available from prestig...          1\n",
       "2   ham  Greetings all. This is to verify your subscrip...          0\n",
       "3  spam  try chauncey may conferred the luscious not co...          1\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...          0\n",
       "5   ham  It's working here. I have departed almost tota...          0\n",
       "6  spam  The OIL sector is going crazy. This is our wee...          1\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...          1\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...          0\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30974,)\n",
      "(30974,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = spam_ham.message\n",
    "y = spam_ham.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "# Use the ff. variables: X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17217    Greetings all, I'm using a homebuilt sonar bas...\n",
      "26323    人妻美・・・良い響き 武勇伝公開！http://get-high.biz/buyuden/問...\n",
      "21976    家庭サービスでストレスの溜まった奥様大ハッスル！即アポ即マンラッシュ！http://airp...\n",
      "29162    Marian Krivos wrote:> Co sa da este pouzivat o...\n",
      "14131    the lego 9v active sensors (i.e., rotation and...\n",
      "Name: message, dtype: object\n",
      "17217    0\n",
      "26323    1\n",
      "21976    1\n",
      "29162    0\n",
      "14131    0\n",
      "Name: label_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- TEST ---\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the count vectorizer and assign it to vect again.\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '000000000000000000000000000000049999999999999e9',\n",
       " '0000000000000000000000000000000500000000000000e9',\n",
       " '0000000000000016666l',\n",
       " '0000000000000017d',\n",
       " '00000000000000e',\n",
       " '000000000000received',\n",
       " '000000000001received',\n",
       " '0000000000status',\n",
       " '0000000001d0',\n",
       " '0000000001l0',\n",
       " '0000000010000000004l0',\n",
       " '0000000016',\n",
       " '000000001d0',\n",
       " '00000000message',\n",
       " '00000000x',\n",
       " '00000001',\n",
       " '00000001content',\n",
       " '00000001irdecode',\n",
       " '00000004',\n",
       " '00000010',\n",
       " '00000010pwm',\n",
       " '00000011',\n",
       " '0000001196',\n",
       " '00000049',\n",
       " '0000005',\n",
       " '0000006hz',\n",
       " '000000eb',\n",
       " '000001',\n",
       " '00000100',\n",
       " '00000100shaftencoder',\n",
       " '00000111',\n",
       " '000001bdaaa0',\n",
       " '000001bdb744',\n",
       " '000001bdc5a5',\n",
       " '000001bdcaf3',\n",
       " '000001bdd411',\n",
       " '000001bdd98c',\n",
       " '000001bdda70',\n",
       " '000001bde0a0',\n",
       " '000001bed6b7',\n",
       " '000001c20f35',\n",
       " '000001c642d0',\n",
       " '000001c64310',\n",
       " '000001c64562',\n",
       " '000001c64585',\n",
       " '000001c64615',\n",
       " '000001c64641',\n",
       " '000001c6465f',\n",
       " '000001c6468e',\n",
       " '000001c676b8',\n",
       " '0000020',\n",
       " '0000040',\n",
       " '0000040b',\n",
       " '0000040c',\n",
       " '000005',\n",
       " '0000060',\n",
       " '00000dd0',\n",
       " '00001',\n",
       " '000010',\n",
       " '0000100',\n",
       " '00001000',\n",
       " '00001004',\n",
       " '00001008',\n",
       " '0000100c',\n",
       " '00001010',\n",
       " '00001014',\n",
       " '00001018',\n",
       " '0000101c',\n",
       " '00001023',\n",
       " '00001026',\n",
       " '00001028',\n",
       " '0000102c',\n",
       " '00001030',\n",
       " '00001034',\n",
       " '00001038',\n",
       " '0000103e',\n",
       " '00001040',\n",
       " '00001044',\n",
       " '00001048',\n",
       " '0000104c',\n",
       " '00001050',\n",
       " '00001054',\n",
       " '0000105a',\n",
       " '0000105ci',\n",
       " '0000120',\n",
       " '0000140',\n",
       " '0000160',\n",
       " '00001808',\n",
       " '0000180cmain',\n",
       " '0000200',\n",
       " '0000220',\n",
       " '0000240',\n",
       " '0000260',\n",
       " '00002i',\n",
       " '0000300',\n",
       " '00003001722',\n",
       " '000031',\n",
       " '0000320',\n",
       " '000033',\n",
       " '0000340',\n",
       " '0000360',\n",
       " '00004',\n",
       " '0000400',\n",
       " '0000420',\n",
       " '0000440',\n",
       " '000046',\n",
       " '0000460',\n",
       " '0000500',\n",
       " '0000504',\n",
       " '000061',\n",
       " '000066',\n",
       " '000076',\n",
       " '000092',\n",
       " '00009800',\n",
       " '00009804',\n",
       " '0000bd',\n",
       " '0000bi',\n",
       " '0000bytes',\n",
       " '0000comment',\n",
       " '0000content',\n",
       " '0000d5',\n",
       " '0000date',\n",
       " '0000david',\n",
       " '0000delivered',\n",
       " '0000ff',\n",
       " '0000from',\n",
       " '0000importance',\n",
       " '0000in',\n",
       " '0000institute',\n",
       " '0000instituteof0000',\n",
       " '0000message',\n",
       " '0000mime',\n",
       " '0000nline',\n",
       " '0000nology',\n",
       " '0000nology404',\n",
       " '0000of',\n",
       " '0000organization',\n",
       " '0000our',\n",
       " '0000precedence',\n",
       " '0000received',\n",
       " '0000reply',\n",
       " '0000scott',\n",
       " '0000to',\n",
       " '0000x',\n",
       " '0001',\n",
       " '00010000',\n",
       " '00010000spdseta',\n",
       " '000101376290',\n",
       " '000101bdc5a5',\n",
       " '000101bdcbb7',\n",
       " '000101bed6b7',\n",
       " '000101bedba4',\n",
       " '000101bef4c2',\n",
       " '00010246',\n",
       " '00010246ebx',\n",
       " '000107',\n",
       " '00011',\n",
       " '00014',\n",
       " '0001_mayprod',\n",
       " '0001db',\n",
       " '0001jn',\n",
       " '0001pt',\n",
       " '0001uk',\n",
       " '0001we',\n",
       " '0001x',\n",
       " '0002',\n",
       " '000201bdaabb',\n",
       " '000201bdc8cb',\n",
       " '000201bdcbb8',\n",
       " '000201bef248',\n",
       " '000201c265a3',\n",
       " '000232026900114623590008952623',\n",
       " '00024355',\n",
       " '000255000',\n",
       " '0002ja',\n",
       " '0002k8',\n",
       " '0002phone',\n",
       " '0002q2',\n",
       " '0002rj',\n",
       " '0003',\n",
       " '000301bde673',\n",
       " '000301c634d3',\n",
       " '000301c6430e',\n",
       " '00033577',\n",
       " '0003gy',\n",
       " '0003jh',\n",
       " '0003qj',\n",
       " '0003zh',\n",
       " '0004',\n",
       " '000401bdd670',\n",
       " '000401bde673',\n",
       " '000401bee39f',\n",
       " '000420',\n",
       " '00048z',\n",
       " '0004ek',\n",
       " '0004ti',\n",
       " '0005',\n",
       " '000501bdca45',\n",
       " '000501bdd670',\n",
       " '000501bed6db',\n",
       " '000501c62cfa',\n",
       " '000548',\n",
       " '0005859375',\n",
       " '0005cv',\n",
       " '0005iw',\n",
       " '0006',\n",
       " '000601bdd38d',\n",
       " '000601bed721',\n",
       " '000601bef689',\n",
       " '0006eu',\n",
       " '0006ms',\n",
       " '0006pn',\n",
       " '0006sc',\n",
       " '0006y1',\n",
       " '0006z8',\n",
       " '0007',\n",
       " '000701bee330',\n",
       " '0007051519140',\n",
       " '00077u',\n",
       " '0007ka',\n",
       " '0007mt',\n",
       " '0008',\n",
       " '000801c59181',\n",
       " '0009',\n",
       " '000901c0e23e',\n",
       " '0009lcdrout',\n",
       " '000a',\n",
       " '000a01bde6a3',\n",
       " '000a01bdea63',\n",
       " '000abpz20',\n",
       " '000antiprotons',\n",
       " '000audre',\n",
       " '000b01c66cb8',\n",
       " '000bachelor',\n",
       " '000barrels',\n",
       " '000br',\n",
       " '000c',\n",
       " '000c01bdcdc7',\n",
       " '000c01c6714b',\n",
       " '000c01c67da1',\n",
       " '000company',\n",
       " '000copies',\n",
       " '000d01c0dff7',\n",
       " '000d93c57554',\n",
       " '000dear',\n",
       " '000doctorate',\n",
       " '000e',\n",
       " '000e01bee437',\n",
       " '000e137038fe07f0ea1e00000e1370ad14f0a238060170380382783800fc7f18157f941b',\n",
       " '000equals',\n",
       " '000eur',\n",
       " '000f01bee9ca',\n",
       " '000f01c0fa97',\n",
       " '000fswc',\n",
       " '000hours',\n",
       " '000i',\n",
       " '000in',\n",
       " '000industry',\n",
       " '000job',\n",
       " '000k',\n",
       " '000km',\n",
       " '000live',\n",
       " '000m',\n",
       " '000master',\n",
       " '000miles',\n",
       " '000mk',\n",
       " '000no',\n",
       " '000or',\n",
       " '000over',\n",
       " '000person',\n",
       " '000rpm',\n",
       " '000solar',\n",
       " '000some',\n",
       " '000stipend',\n",
       " '000students',\n",
       " '000summary',\n",
       " '000t',\n",
       " '000this',\n",
       " '000uponcompletion',\n",
       " '000visitors',\n",
       " '000yes',\n",
       " '000you',\n",
       " '000контактные',\n",
       " '000アブノーマル1時間',\n",
       " '000元',\n",
       " '000元以內',\n",
       " '000円',\n",
       " '000円のみが必要となりますが',\n",
       " '000円不要',\n",
       " '000性感ノーマル',\n",
       " '001',\n",
       " '0010',\n",
       " '00100000',\n",
       " '00100000spdsetb',\n",
       " '00100001',\n",
       " '001001bedde0',\n",
       " '001001bee9ca',\n",
       " '001001befa5e',\n",
       " '001001bf09ef',\n",
       " '00101380381e0700ea1fff5b13f8ea17e00010c7fca6ea11f8ea120cea1c07381803801210380001c0a214e0a4127012f0a200e013c01280ea4003148038200700ea1006ea0c1cea03f013227ea018',\n",
       " '0011',\n",
       " '001101bdd428',\n",
       " '001111111',\n",
       " '0012',\n",
       " '001201bee9d7',\n",
       " '001201beedd8',\n",
       " '00126',\n",
       " '0013',\n",
       " '0014',\n",
       " '001401bf04c9',\n",
       " '001401bf09f4',\n",
       " '0015',\n",
       " '001501bde71a',\n",
       " '001532edt',\n",
       " '0016',\n",
       " '001601bdd428',\n",
       " '001601bde7b0',\n",
       " '0017',\n",
       " '001701bdd73e',\n",
       " '001701bde82b',\n",
       " '001701bed5b2',\n",
       " '001701bef454',\n",
       " '0018',\n",
       " '001801bde88a',\n",
       " '001801beda0f',\n",
       " '001888',\n",
       " '0019',\n",
       " '00191',\n",
       " '001a',\n",
       " '001a01bef1c4',\n",
       " '001aa',\n",
       " '001b01bf0a4a',\n",
       " '001c',\n",
       " '001d',\n",
       " '001e133000231370ea438014e01283ea8700a2380701c0120ea3381c0380a4eb0700a35bea0c3eea03ceea000ea25b1260eaf0381330485aea80c0ea4380003ec7fc141f7b9418',\n",
       " '001e1360002313e0ea4380eb81c01283ea8701a238070380120ea3381c0700a31408eb0e101218121ceb1e20ea0c263807c3c015157b941a',\n",
       " '001eb1ec',\n",
       " '001eboard',\n",
       " '001eeb60e00023ebe0f0384380e1eb81c000831470d887011330a23907038020120ea3391c070040a31580a2ec0100130f380c0b02380613843803e0f81c157b9420',\n",
       " '001f01bdd431',\n",
       " '001f01c0faab',\n",
       " '001f01c275ca',\n",
       " '001fb512f8391e03c03800181418123038200780a200401410a2eb0f001280a200001400131ea45ba45ba45ba4485aa41203b5fc1d2277a123',\n",
       " '001fboard',\n",
       " '001fd',\n",
       " '001hetg',\n",
       " '001http',\n",
       " '001kp',\n",
       " '001mk',\n",
       " '002',\n",
       " '0020',\n",
       " '002001bdd439',\n",
       " '00203228888',\n",
       " '0020afec18ca',\n",
       " '0020j',\n",
       " '0021',\n",
       " '002101bdd459',\n",
       " '00212',\n",
       " '0022',\n",
       " '002201bdd548',\n",
       " '002249',\n",
       " '00228',\n",
       " '002289481249mail',\n",
       " '0022uf',\n",
       " '0023',\n",
       " '002301bdd548',\n",
       " '002301c0faae',\n",
       " '002301c23827',\n",
       " '002321',\n",
       " '00233',\n",
       " '0024',\n",
       " '002401bdd548',\n",
       " '002401c66aeb',\n",
       " '0024________________email',\n",
       " '0025',\n",
       " '002501c22041',\n",
       " '0025fax',\n",
       " '0026',\n",
       " '002601c66a38',\n",
       " '0027',\n",
       " '002712est',\n",
       " '0028',\n",
       " '002801c13bab',\n",
       " '0028ii',\n",
       " '0029',\n",
       " '002930_voxinfo',\n",
       " '0029817706609725333l434294481',\n",
       " '002983',\n",
       " '0029porta',\n",
       " '002_dragon004200943940content',\n",
       " '002_dragon008535651103',\n",
       " '002_dragon013699393919',\n",
       " '002_dragon019357534987content',\n",
       " '002_dragon020181421106',\n",
       " '002_dragon032685489904content',\n",
       " '002_dragon034150072259',\n",
       " '002_dragon034633567807content',\n",
       " '002_dragon039925383399content',\n",
       " '002_dragon040476364422',\n",
       " '002_dragon048889247829content',\n",
       " '002_dragon056675156800',\n",
       " '002_dragon058285243905content',\n",
       " '002_dragon060280103893content',\n",
       " '002_dragon073148149514',\n",
       " '002_dragon074457059520',\n",
       " '002_dragon077329414837',\n",
       " '002_dragon080566096389content',\n",
       " '002_dragon092734619076content',\n",
       " '002_dragon100455099132content',\n",
       " '002_dragon108076263577content',\n",
       " '002_dragon108468622097content',\n",
       " '002_dragon120569444328',\n",
       " '002_dragon122521392039content',\n",
       " '002_dragon128631707502content',\n",
       " '002_dragon133773915096content',\n",
       " '002_dragon136224228356content',\n",
       " '002_dragon138839954923',\n",
       " '002_dragon140844353194',\n",
       " '002_dragon142360745850content',\n",
       " '002_dragon143330654218',\n",
       " '002_dragon149449844292',\n",
       " '002_dragon161509917710',\n",
       " '002_dragon162756092795content',\n",
       " '002_dragon168204929497content',\n",
       " '002_dragon169002695074',\n",
       " '002_dragon169085030403content',\n",
       " '002_dragon176086318908',\n",
       " '002_dragon177944757813content',\n",
       " '002_dragon179326334746',\n",
       " '002_dragon183888777798content',\n",
       " '002_dragon183941553104content',\n",
       " '002_dragon185781585974',\n",
       " '002_dragon186514966961_',\n",
       " '002_dragon188257448684content',\n",
       " '002_dragon188333289331content',\n",
       " '002_dragon189316002559content',\n",
       " '002_dragon193530954717content',\n",
       " '002_dragon196072547742',\n",
       " '002_dragon198189501342content',\n",
       " '002_dragon203013389770content',\n",
       " '002_dragon204052897310',\n",
       " '002_dragon205793002835content',\n",
       " '002_dragon206018273441content',\n",
       " '002_dragon207785784570content',\n",
       " '002_dragon210159025107content',\n",
       " '002_dragon211481662238',\n",
       " '002_dragon212983034666content',\n",
       " '002_dragon213924637584content',\n",
       " '002_dragon214166912429',\n",
       " '002_dragon214895540320',\n",
       " '002_dragon215886918037',\n",
       " '002_dragon216410465126content',\n",
       " '002_dragon231888896784content',\n",
       " '002_dragon233134712957content',\n",
       " '002_dragon234879898522content',\n",
       " '002_dragon235764159952content',\n",
       " '002_dragon237516939735',\n",
       " '002_dragon239516577637content',\n",
       " '002_dragon240032945636content',\n",
       " '002_dragon248564804421content',\n",
       " '002_dragon249354945590content',\n",
       " '002_dragon249807569787content',\n",
       " '002_dragon254481303756',\n",
       " '002_dragon256918362398',\n",
       " '002_dragon262221859113',\n",
       " '002_dragon264396653478',\n",
       " '002_dragon264441716722content',\n",
       " '002_dragon265325440711content',\n",
       " '002_dragon266209308694content',\n",
       " '002_dragon269013230617content',\n",
       " '002_dragon270367826058content',\n",
       " '002_dragon273382864054content',\n",
       " '002_dragon273895548293',\n",
       " '002_dragon281351071662_',\n",
       " '002_dragon281660342386content',\n",
       " '002_dragon285173245356content',\n",
       " '002_dragon289924567963content',\n",
       " '002_dragon291265061908content',\n",
       " '002_dragon292505557095content',\n",
       " '002_dragon293119990835content',\n",
       " '002_dragon295843020376content',\n",
       " '002_dragon302510766348',\n",
       " '002_dragon302921738635',\n",
       " '002_dragon310127751282content',\n",
       " '002_dragon310651914794content',\n",
       " '002_dragon313149702908',\n",
       " '002_dragon317695925892content',\n",
       " '002_dragon318665289543content',\n",
       " '002_dragon319948883600',\n",
       " '002_dragon320946592690content',\n",
       " '002_dragon322915006407',\n",
       " '002_dragon324589698709content',\n",
       " '002_dragon327437312378content',\n",
       " '002_dragon327643673166content',\n",
       " '002_dragon330573254373content',\n",
       " '002_dragon333436883450content',\n",
       " '002_dragon336214030309content',\n",
       " '002_dragon340834821974',\n",
       " '002_dragon341612040241',\n",
       " '002_dragon343333554216',\n",
       " '002_dragon345724565924content',\n",
       " '002_dragon346394276285content',\n",
       " '002_dragon348016147037content',\n",
       " '002_dragon356616615600content',\n",
       " '002_dragon359805902139content',\n",
       " '002_dragon361767389765',\n",
       " '002_dragon366284922033',\n",
       " '002_dragon370830372714',\n",
       " '002_dragon377070002978content',\n",
       " '002_dragon377441852287',\n",
       " '002_dragon384660614980content',\n",
       " '002_dragon389780210192content',\n",
       " '002_dragon390632298472content',\n",
       " '002_dragon391848222368content',\n",
       " '002_dragon399477789492content',\n",
       " '002_dragon402079065150',\n",
       " '002_dragon402740244099content',\n",
       " '002_dragon409823729458content',\n",
       " '002_dragon410509063251content',\n",
       " '002_dragon411110209560content',\n",
       " '002_dragon413436947052content',\n",
       " '002_dragon415805250710content',\n",
       " '002_dragon416123410162content',\n",
       " '002_dragon425323668785content',\n",
       " '002_dragon431429810021content',\n",
       " '002_dragon431676018905content',\n",
       " '002_dragon432852498332content',\n",
       " '002_dragon435496836113',\n",
       " '002_dragon437917652885content',\n",
       " '002_dragon440034119332',\n",
       " '002_dragon441674338630',\n",
       " '002_dragon442592498835',\n",
       " '002_dragon443472164152content',\n",
       " '002_dragon443689150123content',\n",
       " '002_dragon444004361912content',\n",
       " '002_dragon448288168555content',\n",
       " '002_dragon451319953791',\n",
       " '002_dragon451657700235content',\n",
       " '002_dragon456176210945content',\n",
       " '002_dragon468266803279content',\n",
       " '002_dragon470466639645',\n",
       " '002_dragon473323566965',\n",
       " '002_dragon476540816282content',\n",
       " '002_dragon477399743496content',\n",
       " '002_dragon479331544790content',\n",
       " '002_dragon483579780476content',\n",
       " '002_dragon484358097899content',\n",
       " '002_dragon488902243432',\n",
       " '002_dragon491393046235',\n",
       " '002_dragon495877656850content',\n",
       " '002_dragon503725778714_',\n",
       " '002_dragon504217449345',\n",
       " '002_dragon505110412875',\n",
       " '002_dragon505932322972',\n",
       " '002_dragon506805364816content',\n",
       " '002_dragon508712711421content',\n",
       " '002_dragon512122577234',\n",
       " '002_dragon513692340014content',\n",
       " '002_dragon514676478309content',\n",
       " '002_dragon515128794190',\n",
       " '002_dragon516011979524content',\n",
       " '002_dragon516666948361content',\n",
       " '002_dragon518255923908content',\n",
       " '002_dragon519557785805',\n",
       " '002_dragon520683972230content',\n",
       " '002_dragon522040799568',\n",
       " '002_dragon527791339896content',\n",
       " '002_dragon530821623860content',\n",
       " '002_dragon533304058117_',\n",
       " '002_dragon533835082890content',\n",
       " '002_dragon535670459181content',\n",
       " '002_dragon536989065088content',\n",
       " '002_dragon538638107395content',\n",
       " '002_dragon540629808243content',\n",
       " '002_dragon542105054566content',\n",
       " '002_dragon542522505882content',\n",
       " '002_dragon544018013072content',\n",
       " '002_dragon546536074428content',\n",
       " '002_dragon547081415263content',\n",
       " '002_dragon547831489158',\n",
       " '002_dragon554816776882content',\n",
       " '002_dragon557516700063content',\n",
       " '002_dragon558995758314',\n",
       " '002_dragon560194215614content',\n",
       " '002_dragon561824435930content',\n",
       " '002_dragon563227845761',\n",
       " '002_dragon564322207242content',\n",
       " '002_dragon571434638457',\n",
       " '002_dragon574371893608content',\n",
       " '002_dragon575169100404_',\n",
       " '002_dragon575585758776content',\n",
       " '002_dragon577596397905content',\n",
       " '002_dragon583411697069content',\n",
       " '002_dragon584915480615',\n",
       " '002_dragon585001720044content',\n",
       " '002_dragon585387820253',\n",
       " '002_dragon586232798130content',\n",
       " '002_dragon591660557037content',\n",
       " '002_dragon596828381337content',\n",
       " '002_dragon597439856990',\n",
       " '002_dragon599296306728',\n",
       " '002_dragon607166703191_',\n",
       " '002_dragon610136592431content',\n",
       " '002_dragon610953810273content',\n",
       " '002_dragon619468299972content',\n",
       " '002_dragon623245546434',\n",
       " '002_dragon623495405341content',\n",
       " '002_dragon625493329806content',\n",
       " '002_dragon634337155732content',\n",
       " '002_dragon636962270343content',\n",
       " '002_dragon643501113307',\n",
       " '002_dragon645239832728',\n",
       " '002_dragon645469919759content',\n",
       " '002_dragon647819242747content',\n",
       " '002_dragon648837860654content',\n",
       " '002_dragon660060898871content',\n",
       " '002_dragon660123564464content',\n",
       " '002_dragon664173122785content',\n",
       " '002_dragon669679313152content',\n",
       " '002_dragon671339860625content',\n",
       " '002_dragon671413180375',\n",
       " '002_dragon677407173143_',\n",
       " '002_dragon682176656828',\n",
       " '002_dragon682242077477',\n",
       " '002_dragon683701003467',\n",
       " '002_dragon683848968845',\n",
       " '002_dragon684485696525content',\n",
       " '002_dragon685743176115content',\n",
       " '002_dragon700393232030content',\n",
       " '002_dragon702086349026',\n",
       " '002_dragon706880655832content',\n",
       " '002_dragon710680206378',\n",
       " '002_dragon714483479317content',\n",
       " '002_dragon715506809858content',\n",
       " '002_dragon716684339575_',\n",
       " '002_dragon721447944431content',\n",
       " '002_dragon721496209399content',\n",
       " '002_dragon735922421923content',\n",
       " '002_dragon744366455165',\n",
       " '002_dragon745440808393content',\n",
       " '002_dragon745846869871content',\n",
       " '002_dragon749046174059',\n",
       " '002_dragon749135313276content',\n",
       " '002_dragon749616001928content',\n",
       " '002_dragon749775980445',\n",
       " '002_dragon752042517009content',\n",
       " '002_dragon752940174982content',\n",
       " '002_dragon756883035274content',\n",
       " '002_dragon758472607762',\n",
       " '002_dragon760169235045content',\n",
       " '002_dragon762646400558content',\n",
       " '002_dragon763409779758',\n",
       " '002_dragon773027103006',\n",
       " '002_dragon777504927530',\n",
       " '002_dragon779053823085content',\n",
       " '002_dragon779723947235content',\n",
       " '002_dragon785824725207',\n",
       " '002_dragon785883807422content',\n",
       " '002_dragon787036265046',\n",
       " '002_dragon788617422663',\n",
       " '002_dragon789549662168content',\n",
       " '002_dragon790560539053',\n",
       " '002_dragon790568223600',\n",
       " '002_dragon796954387895content',\n",
       " '002_dragon799105077372',\n",
       " '002_dragon803951708982content',\n",
       " '002_dragon805058253897content',\n",
       " '002_dragon806793363072',\n",
       " '002_dragon809654126877_',\n",
       " '002_dragon809864011866content',\n",
       " '002_dragon813633483461content',\n",
       " '002_dragon813978104655',\n",
       " '002_dragon820046601046content',\n",
       " '002_dragon821031089314content',\n",
       " '002_dragon833788956448_',\n",
       " '002_dragon835344230368content',\n",
       " '002_dragon835873675296content',\n",
       " '002_dragon836071345290',\n",
       " '002_dragon837387913413content',\n",
       " '002_dragon838552296986',\n",
       " '002_dragon844804994340content',\n",
       " '002_dragon852494520224',\n",
       " '002_dragon853396716332content',\n",
       " '002_dragon859035731542',\n",
       " '002_dragon866142856789',\n",
       " '002_dragon871663965498',\n",
       " '002_dragon872235195865content',\n",
       " '002_dragon875584409480content',\n",
       " '002_dragon882261761834',\n",
       " '002_dragon882895304044content',\n",
       " '002_dragon887388321534content',\n",
       " '002_dragon890168734255',\n",
       " '002_dragon890932882408content',\n",
       " '002_dragon898049280100content',\n",
       " '002_dragon908062144026content',\n",
       " '002_dragon912634163458content',\n",
       " '002_dragon917066359101',\n",
       " '002_dragon926841011669content',\n",
       " '002_dragon943687789736',\n",
       " '002_dragon953322195972content',\n",
       " '002_dragon955500430856content',\n",
       " '002_dragon956476021852content',\n",
       " '002_dragon959715935339content',\n",
       " '002_dragon966708873484content',\n",
       " '002_dragon966803059116content',\n",
       " '002_dragon975760983408content',\n",
       " '002_dragon975935048487content',\n",
       " '002_dragon980145547667content',\n",
       " '002_dragon981554492198content',\n",
       " '002_dragon984547041819',\n",
       " '002_dragon986057447477content',\n",
       " '002_dragon993740048225content',\n",
       " '002_dragon998760730906',\n",
       " '002_dragon998895130427content',\n",
       " '002a01c2724f',\n",
       " '002br',\n",
       " '002d01c26659',\n",
       " '002d01c66d57',\n",
       " '002d16e0',\n",
       " '002d16e0content',\n",
       " '002data',\n",
       " '002e62',\n",
       " '002f40f4',\n",
       " '002hn',\n",
       " '002letg',\n",
       " '002mk',\n",
       " '002s5',\n",
       " '002time',\n",
       " '003',\n",
       " '0030',\n",
       " '003001bee908',\n",
       " '00301320383e01e0383fffc0148014005b13f8ea33c00030c7fca4ea31fcea37ff383e0fc0383807e0ea3003000013f0a214f8a21238127c12fea200fc13f0a2387007e0003013c0383c1f80380fff00ea03f815207d9f1c',\n",
       " '0031',\n",
       " '00316',\n",
       " '0031630926532',\n",
       " '0031847131601',\n",
       " '0032',\n",
       " '003201c67c38',\n",
       " '0033',\n",
       " '003301beebdc',\n",
       " '003366',\n",
       " '003399',\n",
       " '0034',\n",
       " '0034pulse_default',\n",
       " '0034tcnt',\n",
       " '0035',\n",
       " '003501beebdf',\n",
       " '00353241',\n",
       " '0036',\n",
       " '0037',\n",
       " '0038',\n",
       " '003801c67dab',\n",
       " '0039',\n",
       " '003901beebdf',\n",
       " '003901c67c7a',\n",
       " '003_dragon056507828553_',\n",
       " '003_dragon301619060429_',\n",
       " '003_dragon340468286956_',\n",
       " '003_dragon346143145919_',\n",
       " '003_dragon402596564128_',\n",
       " '003_dragon426402787230_',\n",
       " '003_dragon744672031743_',\n",
       " '003_dragon838556541118_',\n",
       " '003_dragon899887122059_',\n",
       " '003br',\n",
       " '003c',\n",
       " '003c01c0fb80',\n",
       " '003f',\n",
       " '003fax',\n",
       " '003nl',\n",
       " '003pt',\n",
       " '004',\n",
       " '0040',\n",
       " '0040095e21234',\n",
       " '004093',\n",
       " '0040b0b1',\n",
       " '0040b0b10069f628',\n",
       " '0040b530',\n",
       " '0041',\n",
       " '004101c67c3c',\n",
       " '0041asmallu',\n",
       " '0042',\n",
       " '004201beebf9',\n",
       " '0043',\n",
       " '0043c77a',\n",
       " '0043fec0',\n",
       " '0044',\n",
       " '004499',\n",
       " '0044eb9c',\n",
       " '0044f6dc',\n",
       " '0045',\n",
       " '0045subroutine_servo_a5_init',\n",
       " '0046',\n",
       " '00465',\n",
       " '00466',\n",
       " '00467',\n",
       " '00468078',\n",
       " '0046937f',\n",
       " '00469d74',\n",
       " '00469d76',\n",
       " '0047',\n",
       " '0048',\n",
       " '004801c67e59',\n",
       " '0049',\n",
       " '004901c20fff',\n",
       " '0049servo_a5_pulse',\n",
       " '004all',\n",
       " '004c',\n",
       " '004d01c21029',\n",
       " '004nl',\n",
       " '005',\n",
       " '0050',\n",
       " '005004',\n",
       " '0050servo_a5_int',\n",
       " '005135',\n",
       " '0052',\n",
       " '0052servo_bit',\n",
       " '0053',\n",
       " '005301beedb7',\n",
       " '0054',\n",
       " '0055',\n",
       " '0056',\n",
       " '0057',\n",
       " '0058',\n",
       " '0059',\n",
       " '0059variable_servo_a5_pulse',\n",
       " '005a',\n",
       " '005amicrosoft',\n",
       " '005aupdate',\n",
       " '005c',\n",
       " '005c01c210d2',\n",
       " '005d01bf6f13',\n",
       " '005hn',\n",
       " '005la',\n",
       " '005mk',\n",
       " '006',\n",
       " '0060',\n",
       " '0061',\n",
       " '0063',\n",
       " '00632d93',\n",
       " '0063825485257156_',\n",
       " '0063825485257156_content',\n",
       " '0063825785257156_',\n",
       " '0063825785257156_content',\n",
       " '00638260',\n",
       " '0063servo_enable',\n",
       " '0064',\n",
       " '006489',\n",
       " '0064setup_gap',\n",
       " '0065',\n",
       " '0066',\n",
       " '006601c210db',\n",
       " '00664e75',\n",
       " '00667',\n",
       " '00667280',\n",
       " '0066993785257156_',\n",
       " '0066993785257156_content',\n",
       " '0066993a85257156_',\n",
       " '0066993a85257156_content',\n",
       " '00669945',\n",
       " '006701c210dd',\n",
       " '006765d8',\n",
       " '0067tctl1',\n",
       " '0068',\n",
       " '00681b6c',\n",
       " '0068a474',\n",
       " '0068a574',\n",
       " '0068bdbc',\n",
       " '0068da84',\n",
       " '0068uf',\n",
       " '0068uff',\n",
       " '0069',\n",
       " '00690340',\n",
       " '0069d154',\n",
       " '0069f5b8',\n",
       " '0069f5e0',\n",
       " '0069f5e0ecx',\n",
       " '0069f628',\n",
       " '0069fa36',\n",
       " '0069fcf8',\n",
       " '006a',\n",
       " '006a0604',\n",
       " '006b57d8',\n",
       " '006bb7f8',\n",
       " '006c',\n",
       " '006c2ce4',\n",
       " '006c67cc',\n",
       " '006e',\n",
       " '006hn',\n",
       " '006hz',\n",
       " '006karnatakaindiaph',\n",
       " '006la',\n",
       " '006mk',\n",
       " '006nl',\n",
       " '006ov',\n",
       " '006performing',\n",
       " '006s1',\n",
       " '006s1_bias_avg',\n",
       " '007',\n",
       " '0070',\n",
       " '007083ac',\n",
       " '0071',\n",
       " '00717',\n",
       " '0072',\n",
       " '0072for',\n",
       " '0073',\n",
       " '00731864',\n",
       " '00734d74',\n",
       " '0074',\n",
       " '0075',\n",
       " '0076',\n",
       " '0076194298',\n",
       " '00762',\n",
       " '0077',\n",
       " '0077author',\n",
       " '0078',\n",
       " '0078email',\n",
       " '0078title',\n",
       " '0079',\n",
       " '00794d20',\n",
       " '00795ce0',\n",
       " '00798ab0',\n",
       " '007a4e40',\n",
       " '007a5580',\n",
       " '007b0100',\n",
       " '007b5860',\n",
       " '007br',\n",
       " '007cb350',\n",
       " '007f40',\n",
       " '007fb512f839780780780060141800401408a300c0140c00801404a400001400b3a3497e3801fffe1e227ea123',\n",
       " '007fb61280a2397e03f80f00781407007014030060140100e015c0a200c01400a400001500b3a248b512f0a222227ea127',\n",
       " '007fb8fca39039c00ff801d87e00ec003f007c82007882a200708200f01780a3481603a5c792c7fcb3aa017fb6fca331307daf38',\n",
       " '007fd',\n",
       " '007parkerbros',\n",
       " '007you',\n",
       " '008',\n",
       " '0080',\n",
       " '00800',\n",
       " '008000',\n",
       " '0081',\n",
       " '0082',\n",
       " '0082toc3',\n",
       " '0083',\n",
       " '0083903358',\n",
       " '0083903358caveats',\n",
       " '0084',\n",
       " '008482',\n",
       " '0085',\n",
       " '0085weekly',\n",
       " '0086',\n",
       " '0087',\n",
       " '008723514',\n",
       " '0087411652337',\n",
       " '0088',\n",
       " '0088a100',\n",
       " '0088cforc',\n",
       " '0088office',\n",
       " '0089',\n",
       " '0089535',\n",
       " '0089tmsk1',\n",
       " '008br',\n",
       " '008cddec',\n",
       " '008ov',\n",
       " '008scan1',\n",
       " '008scan1testa',\n",
       " '009',\n",
       " '0090',\n",
       " '00901a',\n",
       " '0091',\n",
       " '0092',\n",
       " '0093',\n",
       " '0093according',\n",
       " '0093bac',\n",
       " '0093calls',\n",
       " '0093contact',\n",
       " '0093no',\n",
       " '0093subroutine_initialize_module',\n",
       " '0095',\n",
       " '0095setup_pulse',\n",
       " '0096',\n",
       " '0097',\n",
       " '0097612',\n",
       " '0097616095',\n",
       " '0097616095a',\n",
       " '0098',\n",
       " '009801c29c90',\n",
       " '0098d3',\n",
       " '0099',\n",
       " '009901c2119a',\n",
       " '009901c29c95',\n",
       " '0099ff',\n",
       " '009a01c29c9a',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "X_dtm = vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step using the fit_transform method\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30974x190382 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3080670 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "# This should be:\n",
    "# <23230x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
    "# \twith 2305787 stored elements in Compressed Sparse Row format>\n",
    "X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dtm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "# use the nb variable\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm and the fit() method\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm using the predict() function\n",
    "y_pred_class = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98579545454545459"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2906,   11],\n",
       "       [  99, 4728]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9671    0.9962    0.9814      2917\n",
      "          1     0.9977    0.9795    0.9885      4827\n",
      "\n",
      "avg / total     0.9861    0.9858    0.9858      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+000,   1.11898685e-217,   8.10135549e-161, ...,\n",
       "         1.00000000e+000,   1.50426287e-053,   4.64788362e-017])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970144937355645"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190382"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X using get_feature_names()\n",
    "# its length should be 161925\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '000000000000000000000000000000049999999999999e9',\n",
       " '0000000000000000000000000000000500000000000000e9',\n",
       " '0000000000000016666l',\n",
       " '0000000000000017d',\n",
       " '00000000000000e',\n",
       " '000000000000received',\n",
       " '000000000001received',\n",
       " '0000000000status',\n",
       " '0000000001d0',\n",
       " '0000000001l0',\n",
       " '0000000010000000004l0',\n",
       " '0000000016',\n",
       " '000000001d0',\n",
       " '00000000message',\n",
       " '00000000x',\n",
       " '00000001',\n",
       " '00000001content',\n",
       " '00000001irdecode',\n",
       " '00000004',\n",
       " '00000010',\n",
       " '00000010pwm',\n",
       " '00000011',\n",
       " '0000001196',\n",
       " '00000049',\n",
       " '0000005',\n",
       " '0000006hz',\n",
       " '000000eb',\n",
       " '000001',\n",
       " '00000100',\n",
       " '00000100shaftencoder',\n",
       " '00000111',\n",
       " '000001bdaaa0',\n",
       " '000001bdb744',\n",
       " '000001bdc5a5',\n",
       " '000001bdcaf3',\n",
       " '000001bdd411',\n",
       " '000001bdd98c',\n",
       " '000001bdda70',\n",
       " '000001bde0a0',\n",
       " '000001bed6b7',\n",
       " '000001c20f35',\n",
       " '000001c642d0']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "X_train_tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['３ｄバーチャルｓｅｘメーカー',\n",
       " '４名紹介http',\n",
       " '４月度新規メンバー様応援企画パーティー開催予定',\n",
       " '４月２３日',\n",
       " '５月までのようなので興味のある方はお早めに',\n",
       " '５月中週末３人か４人ぐらいで',\n",
       " '５００円分のポイントが完全無料で自動追加されます',\n",
       " '６名のみとなります',\n",
       " 'ａ型',\n",
       " 'ａ美様現在未亡人でいらっしゃいます',\n",
       " 'ｂ９６',\n",
       " 'ｆカップ',\n",
       " 'ｇａｌ誌多数掲載',\n",
       " 'ｇｏｏｄ',\n",
       " 'ｇｒａｎｄｅｅ',\n",
       " 'ｇｒａｎｄｅｅの理念やシステムのご紹介',\n",
       " 'ｇｗこそ出会いのチャンスhttp',\n",
       " 'ｇｗです',\n",
       " 'ｇｗはこういう女の子と過ごしたいっす',\n",
       " 'ｇｗ特典あり',\n",
       " 'ｈなこと大好きな人ばかり',\n",
       " 'ｈな女の子が多いので',\n",
       " 'ｈな欲望や願望を胸に秘め',\n",
       " 'ｈにそんなに興味なかったのと少し怖いのもあるため',\n",
       " 'ｈのお相手しただけで',\n",
       " 'ｈゲームメーカーの決定版',\n",
       " 'ｈ度',\n",
       " 'ｈ目的の出会いも簡単です',\n",
       " 'ｈ８６',\n",
       " 'ｋ村',\n",
       " 'ｍ子様セーリングクルーザーをお持ちで',\n",
       " 'ｍ字開脚オナニーを机の下から盗撮',\n",
       " 'ｍａｉｌでのサポートは２４時間対応です',\n",
       " 'ｎ藤',\n",
       " 'ｏｌ',\n",
       " 'ｐｃ',\n",
       " 'ｐｃから簡単プロフィール作成',\n",
       " 'ｓクラス専門店',\n",
       " 'ｓ子様秘密が条件で',\n",
       " 'ｓｅｘを求めている',\n",
       " 'ｓｅｘを求めているのです',\n",
       " 'ｓｍ',\n",
       " 'ｔ165',\n",
       " 'ｔバックは',\n",
       " 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね',\n",
       " 'ｔバックを購入しました',\n",
       " 'ｔ島',\n",
       " 'ｔ谷',\n",
       " 'ｗ６２',\n",
       " 'ｙ里様お互いがくつろげるような']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "X_train_tokens[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.70100000e+03,   3.37000000e+02,   3.00000000e+02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.54300000e+03,   5.43700000e+03,   2.00000000e+00, ...,\n",
       "          2.00000000e+00,   4.00000000e+00,   2.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 190382)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1701.,   337.,   300., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.54300000e+03,   5.43700000e+03,   2.00000000e+00, ...,\n",
       "         2.00000000e+00,   4.00000000e+00,   2.00000000e+00])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>1701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>5437.0</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000000000000000000000000000000049999999999999e9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000000000000000000000000000000500000000000000e9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000000000000016666l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000000000000017d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00000000000000e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000000000000received</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000000000001received</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000000000status</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0000000001d0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0000000001l0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0000000010000000004l0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0000000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000000001d0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00000000message</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00000000x</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00000001content</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00000001irdecode</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00000010pwm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190352</th>\n",
       "      <td>ｈなこと大好きな人ばかり</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190353</th>\n",
       "      <td>ｈな女の子が多いので</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190354</th>\n",
       "      <td>ｈな欲望や願望を胸に秘め</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190355</th>\n",
       "      <td>ｈにそんなに興味なかったのと少し怖いのもあるため</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190356</th>\n",
       "      <td>ｈのお相手しただけで</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190357</th>\n",
       "      <td>ｈゲームメーカーの決定版</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190358</th>\n",
       "      <td>ｈ度</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190359</th>\n",
       "      <td>ｈ目的の出会いも簡単です</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190360</th>\n",
       "      <td>ｈ８６</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190361</th>\n",
       "      <td>ｋ村</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190362</th>\n",
       "      <td>ｍ子様セーリングクルーザーをお持ちで</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190363</th>\n",
       "      <td>ｍ字開脚オナニーを机の下から盗撮</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190364</th>\n",
       "      <td>ｍａｉｌでのサポートは２４時間対応です</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190365</th>\n",
       "      <td>ｎ藤</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190366</th>\n",
       "      <td>ｏｌ</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190367</th>\n",
       "      <td>ｐｃ</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190368</th>\n",
       "      <td>ｐｃから簡単プロフィール作成</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190369</th>\n",
       "      <td>ｓクラス専門店</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190370</th>\n",
       "      <td>ｓ子様秘密が条件で</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190371</th>\n",
       "      <td>ｓｅｘを求めている</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190372</th>\n",
       "      <td>ｓｅｘを求めているのです</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190373</th>\n",
       "      <td>ｓｍ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190374</th>\n",
       "      <td>ｔ165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190375</th>\n",
       "      <td>ｔバックは</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190376</th>\n",
       "      <td>ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190377</th>\n",
       "      <td>ｔバックを購入しました</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190378</th>\n",
       "      <td>ｔ島</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190379</th>\n",
       "      <td>ｔ谷</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190380</th>\n",
       "      <td>ｗ６２</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190381</th>\n",
       "      <td>ｙ里様お互いがくつろげるような</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   token  spam_count  \\\n",
       "0                                                     00      3543.0   \n",
       "1                                                    000      5437.0   \n",
       "2                                                   0000         2.0   \n",
       "3                                                 000000        29.0   \n",
       "4                                                0000000         0.0   \n",
       "5                                               00000000         0.0   \n",
       "6                                              000000000         0.0   \n",
       "7                                         00000000000000         0.0   \n",
       "8        000000000000000000000000000000049999999999999e9         0.0   \n",
       "9       0000000000000000000000000000000500000000000000e9         0.0   \n",
       "10                                  0000000000000016666l         0.0   \n",
       "11                                     0000000000000017d         0.0   \n",
       "12                                       00000000000000e         0.0   \n",
       "13                                  000000000000received         0.0   \n",
       "14                                  000000000001received         0.0   \n",
       "15                                      0000000000status         0.0   \n",
       "16                                          0000000001d0         0.0   \n",
       "17                                          0000000001l0         0.0   \n",
       "18                                 0000000010000000004l0         0.0   \n",
       "19                                            0000000016         0.0   \n",
       "20                                           000000001d0         0.0   \n",
       "21                                       00000000message         0.0   \n",
       "22                                             00000000x         0.0   \n",
       "23                                              00000001         0.0   \n",
       "24                                       00000001content         0.0   \n",
       "25                                      00000001irdecode         0.0   \n",
       "26                                              00000004         0.0   \n",
       "27                                              00000010         0.0   \n",
       "28                                           00000010pwm         0.0   \n",
       "29                                              00000011         0.0   \n",
       "...                                                  ...         ...   \n",
       "190352                                      ｈなこと大好きな人ばかり         6.0   \n",
       "190353                                        ｈな女の子が多いので         1.0   \n",
       "190354                                      ｈな欲望や願望を胸に秘め         6.0   \n",
       "190355                          ｈにそんなに興味なかったのと少し怖いのもあるため        64.0   \n",
       "190356                                        ｈのお相手しただけで         2.0   \n",
       "190357                                      ｈゲームメーカーの決定版        64.0   \n",
       "190358                                                ｈ度        45.0   \n",
       "190359                                      ｈ目的の出会いも簡単です         1.0   \n",
       "190360                                               ｈ８６         4.0   \n",
       "190361                                                ｋ村         2.0   \n",
       "190362                                ｍ子様セーリングクルーザーをお持ちで         2.0   \n",
       "190363                                  ｍ字開脚オナニーを机の下から盗撮        68.0   \n",
       "190364                               ｍａｉｌでのサポートは２４時間対応です        19.0   \n",
       "190365                                                ｎ藤         2.0   \n",
       "190366                                                ｏｌ        98.0   \n",
       "190367                                                ｐｃ        97.0   \n",
       "190368                                    ｐｃから簡単プロフィール作成        97.0   \n",
       "190369                                           ｓクラス専門店       148.0   \n",
       "190370                                         ｓ子様秘密が条件で         2.0   \n",
       "190371                                         ｓｅｘを求めている         2.0   \n",
       "190372                                      ｓｅｘを求めているのです        28.0   \n",
       "190373                                                ｓｍ         5.0   \n",
       "190374                                              ｔ165         2.0   \n",
       "190375                                             ｔバックは         6.0   \n",
       "190376               ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね        11.0   \n",
       "190377                                       ｔバックを購入しました         2.0   \n",
       "190378                                                ｔ島         2.0   \n",
       "190379                                                ｔ谷         2.0   \n",
       "190380                                               ｗ６２         4.0   \n",
       "190381                                   ｙ里様お互いがくつろげるような         2.0   \n",
       "\n",
       "        ham_count  \n",
       "0          1701.0  \n",
       "1           337.0  \n",
       "2           300.0  \n",
       "3            33.0  \n",
       "4             0.0  \n",
       "5             4.0  \n",
       "6            11.0  \n",
       "7             6.0  \n",
       "8             1.0  \n",
       "9             1.0  \n",
       "10            1.0  \n",
       "11            1.0  \n",
       "12            1.0  \n",
       "13            1.0  \n",
       "14           22.0  \n",
       "15            0.0  \n",
       "16            1.0  \n",
       "17            1.0  \n",
       "18            1.0  \n",
       "19            1.0  \n",
       "20            1.0  \n",
       "21            4.0  \n",
       "22           10.0  \n",
       "23           20.0  \n",
       "24            5.0  \n",
       "25            1.0  \n",
       "26            1.0  \n",
       "27            2.0  \n",
       "28            1.0  \n",
       "29            2.0  \n",
       "...           ...  \n",
       "190352        0.0  \n",
       "190353        0.0  \n",
       "190354        0.0  \n",
       "190355        0.0  \n",
       "190356        0.0  \n",
       "190357        0.0  \n",
       "190358        0.0  \n",
       "190359        0.0  \n",
       "190360        0.0  \n",
       "190361        0.0  \n",
       "190362        0.0  \n",
       "190363        0.0  \n",
       "190364        0.0  \n",
       "190365        0.0  \n",
       "190366        0.0  \n",
       "190367        0.0  \n",
       "190368        0.0  \n",
       "190369        0.0  \n",
       "190370        0.0  \n",
       "190371        0.0  \n",
       "190372        0.0  \n",
       "190373        0.0  \n",
       "190374        0.0  \n",
       "190375        0.0  \n",
       "190376        0.0  \n",
       "190377        0.0  \n",
       "190378        0.0  \n",
       "190379        0.0  \n",
       "190380        0.0  \n",
       "190381        0.0  \n",
       "\n",
       "[190382 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame(X_train_tokens, columns=['token'])\n",
    "tokens['spam_count'] = spam_token_count\n",
    "tokens['ham_count'] = ham_token_count\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53788</th>\n",
       "      <td>complaintsto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78403</th>\n",
       "      <td>galaad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25938</th>\n",
       "      <td>actualvalues</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50930</th>\n",
       "      <td>chua012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40890</th>\n",
       "      <td>bedetermined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  spam_count  ham_count\n",
       "53788  complaintsto         0.0        0.0\n",
       "78403        galaad         0.0        1.0\n",
       "25938  actualvalues         0.0        0.0\n",
       "50930       chua012         2.0        0.0\n",
       "40890  bedetermined         0.0        2.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows using the sample() method\n",
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8777.,  14453.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141264</th>\n",
       "      <td>roach</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>120nl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>275060john</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61967</th>\n",
       "      <td>dialout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>feelbrowse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  spam_count  ham_count\n",
       "141264       roach         3.0        8.0\n",
       "4384         120nl         1.0        1.0\n",
       "9680    275060john         1.0        1.0\n",
       "61967      dialout         1.0        1.0\n",
       "73202   feelbrowse         2.0        1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['spam_count'] = spam_token_count + 1\n",
    "tokens['ham_count'] = ham_token_count + 1\n",
    "\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141264</th>\n",
       "      <td>roach</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>120nl</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>275060john</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61967</th>\n",
       "      <td>dialout</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>feelbrowse</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  spam_count  ham_count\n",
       "141264       roach    0.000208   0.000911\n",
       "4384         120nl    0.000069   0.000114\n",
       "9680    275060john    0.000069   0.000114\n",
       "61967      dialout    0.000069   0.000114\n",
       "73202   feelbrowse    0.000138   0.000114"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into percentage\n",
    "# by dividing them with nb.class_count_\n",
    "\n",
    "tokens['ham_count'] = tokens['ham_count'] / nb.class_count_[0]\n",
    "tokens['spam_count'] = tokens['spam_count'] / nb.class_count_[1]\n",
    "\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141264</th>\n",
       "      <td>roach</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.227730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>120nl</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.607279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>275060john</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.607279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61967</th>\n",
       "      <td>dialout</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.607279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>feelbrowse</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1.214558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  spam_count  ham_count  spam_ratio\n",
       "141264       roach    0.000208   0.000911    0.227730\n",
       "4384         120nl    0.000069   0.000114    0.607279\n",
       "9680    275060john    0.000069   0.000114    0.607279\n",
       "61967      dialout    0.000069   0.000114    0.607279\n",
       "73202   feelbrowse    0.000138   0.000114    1.214558"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens['spam_count'] / tokens['ham_count']\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_count</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0px</td>\n",
       "      <td>0.715561</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>6280.476994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132471</th>\n",
       "      <td>product_table</td>\n",
       "      <td>0.632256</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>5549.313361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>15px</td>\n",
       "      <td>0.198298</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1740.460942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132541</th>\n",
       "      <td>professionaladobe</td>\n",
       "      <td>0.158375</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1390.061095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133021</th>\n",
       "      <td>proms</td>\n",
       "      <td>0.158375</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1390.061095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85631</th>\n",
       "      <td>hereopt</td>\n",
       "      <td>0.126202</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1107.676469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73593</th>\n",
       "      <td>fff</td>\n",
       "      <td>0.119422</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1048.163150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>00you</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1042.697641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53585</th>\n",
       "      <td>compacted_description</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1042.697641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21425</th>\n",
       "      <td>95more</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1042.697641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140250</th>\n",
       "      <td>reviewsretail</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1042.697641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86994</th>\n",
       "      <td>hoodia</td>\n",
       "      <td>0.105930</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>929.743790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57631</th>\n",
       "      <td>cs2</td>\n",
       "      <td>0.104269</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>915.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189321</th>\n",
       "      <td>無料</td>\n",
       "      <td>0.099702</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>875.088701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>13px</td>\n",
       "      <td>0.198713</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>872.052307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47945</th>\n",
       "      <td>cantex</td>\n",
       "      <td>0.099011</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>869.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73571</th>\n",
       "      <td>ff0000</td>\n",
       "      <td>0.084965</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>745.738324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178718</th>\n",
       "      <td>weightzipping</td>\n",
       "      <td>0.083097</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>729.341798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>10px</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>715.981665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42141</th>\n",
       "      <td>bestsellers</td>\n",
       "      <td>0.080399</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>705.657926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82261</th>\n",
       "      <td>greylink</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53586</th>\n",
       "      <td>compacted_image</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132126</th>\n",
       "      <td>proadobe</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151351</th>\n",
       "      <td>sp_cont</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534</th>\n",
       "      <td>5adobe</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>00c</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>collectionadobe</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53587</th>\n",
       "      <td>compacted_price</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>695.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46794</th>\n",
       "      <td>bz</td>\n",
       "      <td>0.120598</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>529.243444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141643</th>\n",
       "      <td>rolex</td>\n",
       "      <td>0.059157</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>519.223345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146188</th>\n",
       "      <td>sensors</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.057879</td>\n",
       "      <td>0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155423</th>\n",
       "      <td>sunbird</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124330</th>\n",
       "      <td>output</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.120428</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174931</th>\n",
       "      <td>voltage</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101823</th>\n",
       "      <td>lcd</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76728</th>\n",
       "      <td>fred</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.062208</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164471</th>\n",
       "      <td>timedx</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.062208</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54123</th>\n",
       "      <td>computing</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.063233</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43637</th>\n",
       "      <td>bmp</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.066424</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30491</th>\n",
       "      <td>analog</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.066538</td>\n",
       "      <td>0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146638</th>\n",
       "      <td>servo</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.069044</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94270</th>\n",
       "      <td>ir</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150947</th>\n",
       "      <td>sonar</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.073374</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128090</th>\n",
       "      <td>pgp</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.075538</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117104</th>\n",
       "      <td>nil</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.401846</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146161</th>\n",
       "      <td>sensor</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.080893</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164173</th>\n",
       "      <td>thu</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104039</th>\n",
       "      <td>linux</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.094907</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113074</th>\n",
       "      <td>motors</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.097414</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103092</th>\n",
       "      <td>libimlib</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.098553</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141394</th>\n",
       "      <td>robot</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.112111</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146260</th>\n",
       "      <td>sep</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.113478</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140555</th>\n",
       "      <td>ribbon</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153052</th>\n",
       "      <td>starship</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.129201</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130358</th>\n",
       "      <td>port</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.143899</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83735</th>\n",
       "      <td>handy</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117493</th>\n",
       "      <td>nodes</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.166116</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117444</th>\n",
       "      <td>node</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.168167</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49517</th>\n",
       "      <td>cert</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.192549</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84705</th>\n",
       "      <td>hb</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.202119</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        token  spam_count  ham_count   spam_ratio\n",
       "2945                      0px    0.715561   0.000114  6280.476994\n",
       "132471          product_table    0.632256   0.000114  5549.313361\n",
       "5543                     15px    0.198298   0.000114  1740.460942\n",
       "132541      professionaladobe    0.158375   0.000114  1390.061095\n",
       "133021                  proms    0.158375   0.000114  1390.061095\n",
       "85631                 hereopt    0.126202   0.000114  1107.676469\n",
       "73593                     fff    0.119422   0.000114  1048.163150\n",
       "1086                    00you    0.118799   0.000114  1042.697641\n",
       "53585   compacted_description    0.118799   0.000114  1042.697641\n",
       "21425                  95more    0.118799   0.000114  1042.697641\n",
       "140250          reviewsretail    0.118799   0.000114  1042.697641\n",
       "86994                  hoodia    0.105930   0.000114   929.743790\n",
       "57631                     cs2    0.104269   0.000114   915.169100\n",
       "189321                     無料    0.099702   0.000114   875.088701\n",
       "4974                     13px    0.198713   0.000228   872.052307\n",
       "47945                  cantex    0.099011   0.000114   869.015914\n",
       "73571                  ff0000    0.084965   0.000114   745.738324\n",
       "178718          weightzipping    0.083097   0.000114   729.341798\n",
       "3890                     10px    0.244724   0.000342   715.981665\n",
       "42141             bestsellers    0.080399   0.000114   705.657926\n",
       "82261                greylink    0.079222   0.000114   695.334187\n",
       "53586         compacted_image    0.079222   0.000114   695.334187\n",
       "132126               proadobe    0.079222   0.000114   695.334187\n",
       "151351                sp_cont    0.079222   0.000114   695.334187\n",
       "15534                  5adobe    0.079222   0.000114   695.334187\n",
       "1018                      00c    0.079222   0.000114   695.334187\n",
       "52578         collectionadobe    0.079222   0.000114   695.334187\n",
       "53587         compacted_price    0.079222   0.000114   695.334187\n",
       "46794                      bz    0.120598   0.000228   529.243444\n",
       "141643                  rolex    0.059157   0.000114   519.223345\n",
       "...                       ...         ...        ...          ...\n",
       "146188                sensors    0.000069   0.057879     0.001195\n",
       "155423                sunbird    0.000069   0.060157     0.001150\n",
       "124330                 output    0.000138   0.120428     0.001149\n",
       "174931                voltage    0.000069   0.061069     0.001133\n",
       "101823                    lcd    0.000069   0.061524     0.001125\n",
       "76728                    fred    0.000069   0.062208     0.001112\n",
       "164471                 timedx    0.000069   0.062208     0.001112\n",
       "54123               computing    0.000069   0.063233     0.001094\n",
       "43637                     bmp    0.000069   0.066424     0.001042\n",
       "30491                  analog    0.000069   0.066538     0.001040\n",
       "146638                  servo    0.000069   0.069044     0.001002\n",
       "94270                      ir    0.000069   0.070411     0.000983\n",
       "150947                  sonar    0.000069   0.073374     0.000943\n",
       "128090                    pgp    0.000069   0.075538     0.000916\n",
       "117104                    nil    0.000346   0.401846     0.000861\n",
       "146161                 sensor    0.000069   0.080893     0.000855\n",
       "164173                    thu    0.000069   0.083969     0.000824\n",
       "104039                  linux    0.000069   0.094907     0.000729\n",
       "113074                 motors    0.000069   0.097414     0.000710\n",
       "103092               libimlib    0.000069   0.098553     0.000702\n",
       "141394                  robot    0.000069   0.112111     0.000617\n",
       "146260                    sep    0.000069   0.113478     0.000610\n",
       "140555                 ribbon    0.000069   0.121226     0.000571\n",
       "153052               starship    0.000069   0.129201     0.000536\n",
       "130358                   port    0.000069   0.143899     0.000481\n",
       "83735                   handy    0.000069   0.163382     0.000423\n",
       "117493                  nodes    0.000069   0.166116     0.000417\n",
       "117444                   node    0.000069   0.168167     0.000411\n",
       "49517                    cert    0.000069   0.192549     0.000359\n",
       "84705                      hb    0.000069   0.202119     0.000342\n",
       "\n",
       "[190382 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26559</th>\n",
       "      <td>adobe</td>\n",
       "      <td>32.741001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  spam_ratio\n",
       "26559  adobe   32.741001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens[tokens['token'] == 'adobe'][['token','spam_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Naive bayes in a function for easier debugging and reading. Also, got confused with the changes to the steps so please just use this as basis. Thanks!\n",
    "\n",
    "### Final result: 99.69% avg f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "FOR ALPHA 0.1\n",
      "Accuracy score 0.996900826446\n",
      "Confusion matrix [[2945    9]\n",
      " [  15 4775]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9949    0.9970    0.9959      2954\n",
      "          1     0.9981    0.9969    0.9975      4790\n",
      "\n",
      "avg / total     0.9969    0.9969    0.9969      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+000   1.00000000e+000   1.06405579e-190 ...,\n",
      "   1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      "AUC 0.998754316358\n",
      "FOR ALPHA 0.4\n",
      "Accuracy score 0.996642561983\n",
      "Confusion matrix [[2945    9]\n",
      " [  17 4773]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9943    0.9970    0.9956      2954\n",
      "          1     0.9981    0.9965    0.9973      4790\n",
      "\n",
      "avg / total     0.9966    0.9966    0.9966      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+000   1.00000000e+000   7.55642558e-134 ...,\n",
      "   1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      "AUC 0.998814388473\n",
      "FOR ALPHA 0.7\n",
      "Accuracy score 0.996771694215\n",
      "Confusion matrix [[2946    8]\n",
      " [  17 4773]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9943    0.9973    0.9958      2954\n",
      "          1     0.9983    0.9965    0.9974      4790\n",
      "\n",
      "avg / total     0.9968    0.9968    0.9968      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+000   1.00000000e+000   2.50830233e-113 ...,\n",
      "   1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      "AUC 0.998889478616\n",
      "FOR ALPHA 1.0\n",
      "Accuracy score 0.996642561983\n",
      "Confusion matrix [[2947    7]\n",
      " [  19 4771]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9936    0.9976    0.9956      2954\n",
      "          1     0.9985    0.9960    0.9973      4790\n",
      "\n",
      "avg / total     0.9967    0.9966    0.9966      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+000   1.00000000e+000   2.77627154e-101 ...,\n",
      "   1.00000000e+000   1.00000000e+000   1.00000000e+000]\n",
      "AUC 0.998827427656\n",
      "FOR ALPHA 1.3\n",
      "Accuracy score 0.996384297521\n",
      "Confusion matrix [[2947    7]\n",
      " [  21 4769]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9929    0.9976    0.9953      2954\n",
      "          1     0.9985    0.9956    0.9971      4790\n",
      "\n",
      "avg / total     0.9964    0.9964    0.9964      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   5.37588782e-93 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998776295685\n",
      "FOR ALPHA 1.6\n",
      "Accuracy score 0.996126033058\n",
      "Confusion matrix [[2947    7]\n",
      " [  23 4767]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9923    0.9976    0.9949      2954\n",
      "          1     0.9985    0.9952    0.9969      4790\n",
      "\n",
      "avg / total     0.9961    0.9961    0.9961      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   8.50361886e-87 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998727849291\n",
      "FOR ALPHA 1.9\n",
      "Accuracy score 0.996255165289\n",
      "Confusion matrix [[2948    6]\n",
      " [  23 4767]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9923    0.9980    0.9951      2954\n",
      "          1     0.9987    0.9952    0.9970      4790\n",
      "\n",
      "avg / total     0.9963    0.9963    0.9963      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   6.54476096e-82 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998684350013\n",
      "FOR ALPHA 2.2\n",
      "Accuracy score 0.995996900826\n",
      "Confusion matrix [[2948    6]\n",
      " [  25 4765]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9916    0.9980    0.9948      2954\n",
      "          1     0.9987    0.9948    0.9968      4790\n",
      "\n",
      "avg / total     0.9960    0.9960    0.9960      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   6.43500431e-78 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998663713474\n",
      "FOR ALPHA 2.5\n",
      "Accuracy score 0.995867768595\n",
      "Confusion matrix [[2948    6]\n",
      " [  26 4764]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9913    0.9980    0.9946      2954\n",
      "          1     0.9987    0.9946    0.9967      4790\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   1.43946581e-74 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998631168523\n",
      "FOR ALPHA 2.8\n",
      "Accuracy score 0.995867768595\n",
      "Confusion matrix [[2948    6]\n",
      " [  26 4764]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9913    0.9980    0.9946      2954\n",
      "          1     0.9987    0.9946    0.9967      4790\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   1.06103632e-71 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998606220927\n",
      "FOR ALPHA 3.0\n",
      "Accuracy score 0.995738636364\n",
      "Confusion matrix [[2948    6]\n",
      " [  27 4763]]\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9909    0.9980    0.9944      2954\n",
      "          1     0.9987    0.9944    0.9965      4790\n",
      "\n",
      "avg / total     0.9958    0.9957    0.9957      7744\n",
      "\n",
      "Calculate predicted probabilities for X_test [  1.00000000e+00   1.00000000e+00   5.30675048e-70 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "AUC 0.998590001456\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEFAULT_STOPS = sklearn.feature_extraction.text.ENGLISH_STOP_WORDS\n",
    "PATH = 'data/spam_ham.csv'\n",
    "RESULTS = []\n",
    "\n",
    "def do_naive_bayes(csv_path=PATH, stop_words=DEFAULT_STOPS, \n",
    "                   alpha=0.1, max_df=.9, min_df=0,\n",
    "                  ngram_range=(0, 4), random_state=None):\n",
    "    # read dataframe from csv\n",
    "    df = pd.read_csv(csv_path, header=0, names=['label', 'location', 'message'])\n",
    "    df = df.drop('location', axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # convert to numerical\n",
    "    df['label_num'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "\n",
    "    # assign to vars\n",
    "    X = df.message\n",
    "    y = df.label_num\n",
    "    \n",
    "    # vectorize dataset and transform into document-term matrix\n",
    "    vect = CountVectorizer(stop_words=stop_words, min_df=min_df, \n",
    "                           max_df=max_df, ngram_range=ngram_range)\n",
    "    X_dtm = vect.fit_transform(X)\n",
    "    \n",
    "    # split into test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dtm, y, random_state=random_state)\n",
    "    \n",
    "    # create multinomial naive bayes\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    # fit to training data\n",
    "    nb.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on test data\n",
    "    y_pred_class = nb.predict(X_test)\n",
    "    \n",
    "    # print metrics\n",
    "    cls_report = classification_report(y_test, y_pred_class, digits=4)\n",
    "    y_pred_prob = nb.predict_proba(X_test)[:, 1]\n",
    "    print(\"FOR ALPHA\", alpha)\n",
    "    print(\"Accuracy score\", metrics.accuracy_score(y_test, y_pred_class))\n",
    "    print(\"Confusion matrix\", metrics.confusion_matrix(y_test, y_pred_class))\n",
    "    print(\"Classification report\")\n",
    "    print(cls_report)\n",
    "    print(\"Calculate predicted probabilities for X_test\", y_pred_prob)\n",
    "    print(\"AUC\", metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "    return cls_report\n",
    "\n",
    "for x in np.arange(0.1, 3.0, .3):\n",
    "    RESULTS.append((x, do_naive_bayes(random_state=0, alpha=x)))\n",
    "RESULTS.append((3.0, do_naive_bayes(random_state=0, alpha=3.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of increasing Alpha on precision and recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbe0d4da908>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe0f3867b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = []\n",
    "precision = []\n",
    "recall = []\n",
    "for a, x in RESULTS:\n",
    "    _x = x.split()\n",
    "    alpha.append(a)\n",
    "    precision.append(_x[-4])\n",
    "    recall.append(_x[-3])\n",
    "\n",
    "print('Effect of increasing Alpha on precision and recall')\n",
    "\n",
    "plt.plot(alpha, precision, label='precision')\n",
    "plt.plot(alpha, recall, label='recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you! \n",
    "\n",
    "## Extremely fun activity! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer (Challenge)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "\n",
    "Tasks:\n",
    "1. **Experiment**, and let the data tell you the best approach!\n",
    "2. Try to reduce or increase the features and get a better score on the previous model. \n",
    "   * Score above a 99.5%? Tell us! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 10: Tuning the Laplacian Correction Factor (Challenge)\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> class sklearn.naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "> Parameters:\t\n",
    "alpha : float, optional (default=1.0)\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "One of the parameters that we can tune in training a Multinomial Naive Bayes Classifier is the Laplacian Correction Factor.\n",
    "\n",
    "Tasks:\n",
    "1. Tweak the correction factor from 0-3 in increments of 0.1, 5, and 10, thus training multiple classifiers.\n",
    "2. Plot the precision-recall curves for these classifiers to compare and contrast."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
