{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOST AI Summer School 2017\n",
    "# Multinomial Naive Bayes Spam Classifier\n",
    "\n",
    "Prepared by Jerelyn Co (ADMU) and Hadrian Paulo Lim (ADMU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.62% 26/61\n",
      "57.38% 35/61\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "p_lakers = .65\n",
    "p_spurs = .35\n",
    "\n",
    "p_lakers_on_spurs = .3\n",
    "p_spurs_on_spurs = .75\n",
    "\n",
    "lak = p_lakers * p_lakers_on_spurs\n",
    "sp = p_spurs * p_spurs_on_spurs\n",
    "\n",
    "total = lak + sp\n",
    "\n",
    "lak = lak / total\n",
    "sp = sp / total\n",
    "print('{0:.2f}%'.format(lak * 100), Fraction(lak).limit_denominator())\n",
    "print('{0:.2f}%'.format(sp * 100), Fraction(sp).limit_denominator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028218694885361547\n",
      "0.006857142857142858\n",
      "Yes, will buy!\n"
     ]
    }
   ],
   "source": [
    "def count(target, src):\n",
    "    n = 0\n",
    "    for x in src:\n",
    "        if x == target:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "def get_prob(target, src):\n",
    "    # args: 'y', age == (2/9, 3/5)\n",
    "    n = 0\n",
    "    m = 0\n",
    "    yeses = 0\n",
    "    nos = 0\n",
    "    for i, x in enumerate(src):\n",
    "        if buys[i] == 'y':\n",
    "            yeses += 1\n",
    "            if x == target:\n",
    "                n += 1\n",
    "        if buys[i] == 'n':\n",
    "            nos += 1\n",
    "            if x == target:\n",
    "                m += 1\n",
    "    return (n / yeses, m / nos)\n",
    "\n",
    "age = 'yymooomyyoymmo'\n",
    "income = 'hhhmlllmlmmmhm'\n",
    "student = 'nnnnyyynyyynyn'\n",
    "credit_rating = 'fefffeefffeefe'\n",
    "buys = 'nnyyynynyyyyyn'\n",
    "\n",
    "buys_comp = len([x for x in buys if x == 'y']) / len(buys)\n",
    "no_buys_comp = len([x for x in buys if x == 'n']) / len(buys) #.357 # 5/14\n",
    "s1 = 1\n",
    "s2 = 1\n",
    "    \n",
    "for x, y in zip('ymyf', [age, income, student, credit_rating]):\n",
    "    _p = get_prob(x, y)\n",
    "    s1 *= _p[0]\n",
    "    s2 *= _p[1]\n",
    "\n",
    "print(s1 * buys_comp)\n",
    "print(s2 * no_buys_comp)\n",
    "\n",
    "print(\"Yes, will buy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "\n",
    "## Step 0: Let's load up the Iris dataset.\n",
    "\n",
    "#### Scikit-learn already has built-in and preformatted datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Step 1: Let's fit the data into a Pandas Dataframe for easier data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data= np.c_[iris_data['data'], iris_data['target']],\n",
    "                     columns= iris_data['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### The Iris dataset in Sci-kit Learn already converted the class labels (target) to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Step 2: Splitting the data to Training and Testing Datasets\n",
    "\n",
    "#### Let's split the data to create train/test sets.\n",
    "\n",
    "#### In this case, we're randomly sampling 20% of the entries to be the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['sepal length (cm)',\n",
    "                                                        'sepal width (cm)',\n",
    "                                                        'petal length (cm)',\n",
    "                                                        'petal width (cm)']], \n",
    "                                                    df[['target']], test_size=0.2, random_state=427)\n",
    "y_train = y_train.values.flatten() # Just some trivial data formatting..\n",
    "y_test = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Step 3: Create and train the Gaussian Naive Bayes Classifier\n",
    "\n",
    "#### We'll be using Sci-kit Learn's Gaussian Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### We fit our training data to the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Now we can use it to predict the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  0.,  0.,  0.,  1.,  2.,  1.,  1.,  0.,  2.,  0.,\n",
       "        1.,  2.,  2.,  1.,  1.,  1.,  0.,  0.,  2.,  2.,  2.,  1.,  2.,\n",
       "        0.,  0.,  2.,  2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score = gnb.predict(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### We can also see the probabilities of the resulting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   3.50693642e-018,   1.12604782e-026],\n",
       "       [  6.98707738e-062,   9.99926096e-001,   7.39041832e-005],\n",
       "       [  1.60036345e-088,   9.87965737e-001,   1.20342630e-002],\n",
       "       [  1.00000000e+000,   7.04345826e-019,   1.86702928e-027],\n",
       "       [  1.00000000e+000,   2.63728803e-017,   3.83336083e-026],\n",
       "       [  1.00000000e+000,   1.83411912e-018,   1.69669459e-027],\n",
       "       [  1.39288475e-053,   9.99995382e-001,   4.61845739e-006],\n",
       "       [  5.90508999e-209,   2.71871956e-010,   1.00000000e+000],\n",
       "       [  5.28070877e-085,   9.98330403e-001,   1.66959665e-003],\n",
       "       [  5.20783809e-077,   9.96794466e-001,   3.20553400e-003],\n",
       "       [  1.00000000e+000,   2.48546795e-014,   3.58920164e-023],\n",
       "       [  1.46057864e-251,   4.17504056e-011,   1.00000000e+000],\n",
       "       [  1.00000000e+000,   3.99136561e-015,   3.71176571e-025],\n",
       "       [  1.63370989e-055,   9.99976241e-001,   2.37585142e-005],\n",
       "       [  3.07162234e-195,   2.41337277e-008,   9.99999976e-001],\n",
       "       [  4.18001852e-121,   1.50769785e-001,   8.49230215e-001],\n",
       "       [  2.64029778e-055,   9.99983719e-001,   1.62813407e-005],\n",
       "       [  4.79811726e-134,   6.29337857e-001,   3.70662143e-001],\n",
       "       [  1.60498532e-042,   9.99998935e-001,   1.06483926e-006],\n",
       "       [  1.00000000e+000,   2.76216425e-017,   2.76284940e-026],\n",
       "       [  1.00000000e+000,   6.37575108e-017,   1.51291961e-025],\n",
       "       [  2.54442592e-239,   2.41853457e-009,   9.99999998e-001],\n",
       "       [  2.97077072e-181,   3.32779736e-005,   9.99966722e-001],\n",
       "       [  3.84527083e-116,   2.20081518e-001,   7.79918482e-001],\n",
       "       [  2.13412653e-074,   9.98752105e-001,   1.24789454e-003],\n",
       "       [  9.96834262e-181,   2.17294854e-006,   9.99997827e-001],\n",
       "       [  1.00000000e+000,   3.50693642e-018,   1.12604782e-026],\n",
       "       [  1.00000000e+000,   5.14481881e-018,   1.21413924e-026],\n",
       "       [  1.62152578e-135,   1.35504405e-002,   9.86449559e-001],\n",
       "       [  1.49213149e-147,   5.08053409e-004,   9.99491947e-001]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Step 4: Assessing Model Performance\n",
    "#### Now, let's see the performance of our Gaussian Naive Bayes Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa     1.0000    1.0000    1.0000        10\n",
      " versicolor     0.9000    1.0000    0.9474         9\n",
      "  virginica     1.0000    0.9091    0.9524        11\n",
      "\n",
      "avg / total     0.9700    0.9667    0.9668        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_score, target_names=iris_data.target_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
