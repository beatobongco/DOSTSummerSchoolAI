{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Census Income Binary Classification dataset\n",
    "\n",
    "A subset of the 1994 Census database, using working adults over the age of 16 with an adjusted income index of > 100.\n",
    "\n",
    "<b>Usage:</b> Classify people using demographics to predict whether a person earns over 50K a year.\n",
    "\n",
    "Related Research: Kohavi, R., Becker, B., (1996). UCI Machine Learning Repository http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Importing our initial libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_0</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   workclass_0  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0            0                      0                    0   \n",
       "1            0                      0                    0   \n",
       "2            0                      0                    0   \n",
       "3            0                      0                    0   \n",
       "4            0                      0                    0   \n",
       "\n",
       "   workclass_Never-worked   ...    native-country_Puerto-Rico  \\\n",
       "0                       0   ...                             0   \n",
       "1                       0   ...                             0   \n",
       "2                       0   ...                             0   \n",
       "3                       0   ...                             0   \n",
       "4                       0   ...                             0   \n",
       "\n",
       "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                        0                     0                      0   \n",
       "1                        0                     0                      0   \n",
       "2                        0                     0                      0   \n",
       "3                        0                     0                      0   \n",
       "4                        0                     0                      0   \n",
       "\n",
       "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  \\\n",
       "0                             1                       0   \n",
       "1                             1                       0   \n",
       "2                             1                       0   \n",
       "3                             1                       0   \n",
       "4                             0                       0   \n",
       "\n",
       "   native-country_Yugoslavia  income  \n",
       "0                          0       0  \n",
       "1                          0       0  \n",
       "2                          0       0  \n",
       "3                          0       0  \n",
       "4                          0       0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "exc_col = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "def read_and_clean(path, exc_col=exc_col):\n",
    "    \"\"\"Load dataset from path and pre-process. \n",
    "    \n",
    "    Strip leading and trailing whitespace.\n",
    "    \n",
    "    returns a DataFrame\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path, delimiter=' *, *', engine='python')\n",
    "    data.replace({'?': 0}, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    cols = data.keys()\n",
    "    \n",
    "    dummied_data = pd.get_dummies(data.drop('income', 1))\n",
    "    dummied_data['income'] = data['income']\n",
    "    dummied_data.replace({\n",
    "        '<=50K': 0,\n",
    "        '>50K': 1\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Creates a dynamic mapping of columns\n",
    "#     map_data = {}\n",
    "\n",
    "#     for col in cols:\n",
    "#         if col not in exc_col:\n",
    "#             map_data[col] = {}\n",
    "#             for idx, val in enumerate(data[col].unique()):\n",
    "#                 map_data[col][val] = idx\n",
    "\n",
    "#             data[col] = data[col].map(map_data[col])\n",
    "#     # OneHotEncoding\n",
    "#     categorical_features = [data.columns.get_loc(k) for k in (set(data.keys()) - set(exc_col) - set(['income']))]\n",
    "#     enc = OneHotEncoder(categorical_features=categorical_features)\n",
    "#     print(categorical_features)\n",
    "#     hot_out = pd.DataFrame(enc.fit_transform(data).toarray(), columns=categorical_features)\n",
    "    \n",
    "    return dummied_data\n",
    "\n",
    "data = read_and_clean('Adult Census Income Binary Classification dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Scaling\n",
    "\n",
    "## Mean normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_feature_scaling(col, data):\n",
    "    \"\"\"Applies mean normalization to a column.\n",
    "    \n",
    "    Modifies data in place.\n",
    "    \"\"\"\n",
    "    _std = np.std(data[col])\n",
    "    _mean = np.mean(data[col])\n",
    "    \n",
    "    data[col] = (data[col] - _mean) / _std\n",
    "\n",
    "for s in ['age', 'fnlwgt', 'education-num', 'capital-gain', \n",
    "          'capital-loss', 'hours-per-week']:\n",
    "    do_feature_scaling(s, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "SPLIT = 7500\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_out = pca.fit_transform(data.drop('income', 1))\n",
    "data2 = pd.DataFrame(pca_out)\n",
    "data2 = data2.set_index(data.index)\n",
    "data2['income'] = data['income']\n",
    "\n",
    "data2 = (data2[data2['income'] == 1].sample(SPLIT, random_state=0)\n",
    "        .append(data2[data2['income']==0].sample(SPLIT, random_state=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 900, 'gamma': 0.01}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.76      0.81      1500\n",
      "          1       0.78      0.88      0.83      1500\n",
      "\n",
      "avg / total       0.83      0.82      0.82      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "SEED = 0\n",
    "RESULTS = {}\n",
    "c = np.arange(100, 1001, 100)\n",
    "g = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# Best C=1000, gamma=0.001\n",
    "def run_svm(label, data, random_state):\n",
    "    tuned_parameters = [\n",
    "        {'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': g, 'C': c},\n",
    "        {'kernel': ['sigmoid'], 'gamma': g, 'C': c},  \n",
    "        {'kernel': ['rbf'], 'gamma': g, 'C': c},\n",
    "        {'kernel': ['linear'], 'C': [1, 100]}, # takes SUPER long\n",
    "                       ]\n",
    "    \n",
    "    X = data.drop(label, 1)\n",
    "    y = data[label]\n",
    "    (X_train, X_test, \n",
    "     y_train, y_test) = train_test_split(X, y, random_state=random_state,\n",
    "                                         test_size=.20, stratify=y)\n",
    "    \n",
    "    clf = GridSearchCV(svm.SVC(random_state=random_state), tuned_parameters, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    return clf\n",
    "\n",
    "clf = run_svm('income', data2, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " * was super slow even with just 500 samples without PCA and feature scaling\n",
    " * PCA: n_components affects the final score\n",
    " * categorical data should not be represented by numbers, should be transformed into columns with 0 or 1\n",
    " * linear took super long\n",
    " * highest f1 possible we found is .84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 2, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 3, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1, 'degree': 4, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 2, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 3, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 10, 'degree': 4, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 2, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 3, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 100, 'degree': 4, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 2, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 3, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       " {'C': 1000, 'degree': 4, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       " {'C': 1, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       " {'C': 1, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       " {'C': 1, 'gamma': 1e-05, 'kernel': 'sigmoid'},\n",
       " {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       " {'C': 10, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       " {'C': 10, 'gamma': 1e-05, 'kernel': 'sigmoid'},\n",
       " {'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       " {'C': 100, 'gamma': 1e-05, 'kernel': 'sigmoid'},\n",
       " {'C': 1000, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       " {'C': 1000, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       " {'C': 1000, 'gamma': 1e-05, 'kernel': 'sigmoid'},\n",
       " {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       " {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       " {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       " {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       " {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       " {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       " {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       " {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       " {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['params']\n",
    "clf.cv_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "save_obj(clf, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
